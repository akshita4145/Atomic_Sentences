{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/train_subset_cleaned.csv')\n",
    "\n",
    "# This gives: -1, 0, 1, 2...\n",
    "df['sentence_id'] = df.index - 1\n",
    "\n",
    "# If you don't want the first row (Alice) to have a row number (i.e. NaN or blank), \n",
    "# you could handle that explicitly before saving.\n",
    "# A common approach is to handle the logic within the DataFrame itself.\n",
    "\n",
    "# To handle the first row (index 0) specifically:\n",
    "df.loc[df.index == 0, 'sentence_id'] = np.nan \n",
    "\n",
    "df['sentence_id'] = df['sentence_id'].astype('Int64')\n",
    "\n",
    "# 3. Save the DataFrame to a new CSV file\n",
    "# We specify index=False because the row numbering is now a regular column named 'RowNumber'.\n",
    "df.to_csv('../data/train_subset_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. The 100 “best” sentence_id values\n",
    "keep_ids = [\n",
    "    1, 2, 3, 4, 5, 6, 9, 10, 12, 17,\n",
    "    18, 19, 23, 26, 32, 38, 39, 40, 42, 44,\n",
    "    45, 46, 48, 49, 51, 52, 55, 57, 59, 61,\n",
    "    62, 63, 64, 66, 67, 69, 72, 74, 75, 77,\n",
    "    79, 81, 85, 86, 93, 94, 96, 97, 100, 101,\n",
    "    103, 105, 106, 108, 109, 113, 114, 116, 117, 118,\n",
    "    119, 120, 121, 122, 124, 125, 126, 128, 129, 131,\n",
    "    132, 133, 134, 135, 136, 137, 138, 139, 144, 146,\n",
    "    150, 151, 152, 153, 156, 157, 159, 162, 163, 167,\n",
    "    168, 169, 171, 172, 173, 174, 175, 177, 178, 180\n",
    "]\n",
    "\n",
    "# 3. Filter to those ids\n",
    "eval_df = df[df[\"sentence_id\"].isin(keep_ids)].copy()\n",
    "\n",
    "# 4. Drop exact duplicate rows, just in case\n",
    "eval_df = eval_df.drop_duplicates()\n",
    "\n",
    "# 5. Save evaluation CSV\n",
    "eval_df.to_csv(\"../data/train_subset_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
