{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy in\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only ADJ advmod managers\n",
      "managers NOUN nsubj approve\n",
      "who PRON nsubj completed\n",
      "completed VERB relcl managers\n",
      "training NOUN dobj completed\n",
      "can AUX aux approve\n",
      "approve VERB ROOT approve\n",
      "budget NOUN compound requests\n",
      "requests NOUN dobj approve\n",
      ". PUNCT punct approve\n"
     ]
    }
   ],
   "source": [
    "##EXAMPLE PARSED SENTENCE WITH SPACY\n",
    "text = \"Only managers who completed training can approve budget requests.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/train_subset_cleaned.csv')\n",
    "cleaned = df['cleaned_text']\n",
    "\n",
    "processed = []\n",
    "\n",
    "for idx, sentence in enumerate(cleaned):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Iterate over each token in the parsed sentence\n",
    "    for token in doc:\n",
    "        processed.append({\n",
    "            \"sentence_id\": idx,\n",
    "            \"sentence_text\": sentence,\n",
    "            \"token_text\": token.text,\n",
    "            \"pos_tag\": token.pos_,\n",
    "            \"dep_relation\": token.dep_,\n",
    "            \"lemma\": token.lemma_,\n",
    "            \"is_stop\": token.is_stop,\n",
    "            \"is_punct\": token.is_punct,\n",
    "        })\n",
    "\n",
    "processed_df = pd.DataFrame(processed)\n",
    "processed_df.to_csv('../data/tokenized_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
